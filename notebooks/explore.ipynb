{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Model Math Exploration\n",
    "\n",
    "Experiment with `Qwen2.5-0.5B` (4-bit MLX) on training problems. Inspect problem types, run the model, and see where it succeeds or fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjtunney/repos/maths-prompt/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: /Users/pjtunney/repos/maths-prompt/models/Qwen2.5-0.5B-4bit\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "from maths_prompt.generator import generate_problems, generate_test_problems\n",
    "from maths_prompt.model import query_model, query_model_batch\n",
    "from maths_prompt.scorer import extract_number, check_answer\n",
    "from maths_prompt.config import MLX_MODEL_PATH\n",
    "\n",
    "print(f\"Model: {MLX_MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Inspect the exact prompt format sent to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system: ''\n",
      "question: '2 + 2'\n",
      "--- formatted prompt ---\n",
      "<|im_start|>system\n",
      "<|im_end|>\n",
      "<|im_start|>user\n",
      "2 + 2 =<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "============================================================\n",
      "system: 'Solve the math expression and output only the number.'\n",
      "question: '2 + 2'\n",
      "--- formatted prompt ---\n",
      "<|im_start|>system\n",
      "Solve the math expression and output only the number.<|im_end|>\n",
      "<|im_start|>user\n",
      "2 + 2 =<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "============================================================\n",
      "system: 'Solve the math expression and output only the number.'\n",
      "question: '(15 + 7) * (3 - 1)'\n",
      "--- formatted prompt ---\n",
      "<|im_start|>system\n",
      "Solve the math expression and output only the number.<|im_end|>\n",
      "<|im_start|>user\n",
      "(15 + 7) * (3 - 1) =<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "from maths_prompt.model import _load, _format_prompt\n",
    "\n",
    "_, tokenizer = _load()\n",
    "\n",
    "examples = [\n",
    "    (\"\", \"2 + 2\"),\n",
    "    (\"Solve the math expression and output only the number.\", \"2 + 2\"),\n",
    "    (\"Solve the math expression and output only the number.\", \"(15 + 7) * (3 - 1)\"),\n",
    "]\n",
    "\n",
    "for system, question in examples:\n",
    "    prompt = _format_prompt(tokenizer, system, question)\n",
    "    print(f\"system: {repr(system)}\")\n",
    "    print(f\"question: {repr(question)}\")\n",
    "    print(\"--- formatted prompt ---\")\n",
    "    print(prompt)\n",
    "    print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Inspect training problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question                                     Answer\n",
      "----------------------------------------------------\n",
      "(39 + 9) - 89                                   -41\n",
      "(94 + 49) * (57 - 26)                          4433\n",
      "45 - 56                                         -11\n",
      "(37 + 24) + (26 - 94)                            -7\n",
      "51 + 21                                          72\n",
      "((65 - 62) - (29 - 44)) - 22 / 22 * 52          -34\n",
      "(6 * 10 + (20 + 35)) * 99                 1.138e+04\n",
      "5 * 97 * 22 * 14 / 7                      2.134e+04\n",
      "45 * 8 - 22 * 10                                140\n",
      "4 - 30                                          -26\n",
      "5 * 16 - 5 / 5                                   79\n",
      "47 * 29                                        1363\n",
      "36 + 39                                          75\n",
      "(67 - 99) + 2 * 41                               50\n",
      "49 * 9                                          441\n",
      "40 + 23                                          63\n",
      "94 - (33 - 70)                                  131\n",
      "4 * 20                                           80\n",
      "57 * 34 - 61 * 97                             -3979\n",
      "(66 + 38) + 63                                  167\n"
     ]
    }
   ],
   "source": [
    "train = generate_problems(20)\n",
    "\n",
    "print(f\"{'Question':<40} {'Answer':>10}\")\n",
    "print(\"-\" * 52)\n",
    "for p in train:\n",
    "    print(f\"{p.question:<40} {p.answer:>10.4g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Inspect test problems (by category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== exponents ===\n",
      "  3 ** 2  →  9.0\n",
      "  2 ** 3  →  8.0\n",
      "  2 ** 3  →  8.0\n",
      "\n",
      "=== modulo ===\n",
      "  769 % 10  →  9.0\n",
      "  724 % 15  →  4.0\n",
      "  801 % 11  →  9.0\n",
      "\n",
      "=== long_chain ===\n",
      "  18 + 95 + 14 + 87 + 95 + 70  →  379.0\n",
      "  20 - 28 - 98 - 44 - 14 - 12 - 49  →  -225.0\n",
      "  13 + 49 + 36 + 59 + 82 + 47  →  286.0\n",
      "\n",
      "=== deeply_nested ===\n",
      "  ((3 + 19) + (14 + 2)) + 1  →  39.0\n",
      "  ((4 + 12) - (12 * 20)) + 9  →  -215.0\n",
      "  ((6 * 12) + (12 * 7)) + 9  →  165.0\n",
      "\n",
      "=== negatives ===\n",
      "  (-33) * 39 + 2  →  -1285.0\n",
      "  (-35) + 8 + 25  →  -2.0\n",
      "  (-39) * 41 + 11  →  -1588.0\n",
      "\n",
      "=== decimals ===\n",
      "  3.5 - 9.0  →  -5.5\n",
      "  9.0 * 5.0  →  45.0\n",
      "  4.0 - 3.0  →  1.0\n",
      "\n",
      "=== large_numbers ===\n",
      "  4611 - 8359  →  -3748.0\n",
      "  6925 + 4150  →  11075.0\n",
      "  7216 + 5422  →  12638.0\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "test = generate_test_problems(70)  # 10 per category\n",
    "by_cat = defaultdict(list)\n",
    "for p in test:\n",
    "    by_cat[p.category].append(p)\n",
    "\n",
    "for cat, problems in by_cat.items():\n",
    "    print(f\"\\n=== {cat} ===\")\n",
    "    for p in problems[:3]:\n",
    "        print(f\"  {p.question}  →  {p.answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run the model on a few problems (no system prompt)\n",
    "\n",
    "This is the raw baseline — no guidance at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (no prompt): 0%\n",
      "\n",
      "✗  Q: (39 + 9) - 89\n",
      "   Expected: -41.0  |  Extracted: 39.0\n",
      "   Model: (39 + 9) - 89 = :=\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "\n",
      "✗  Q: (94 + 49) * (57 - 26)\n",
      "   Expected: 4433.0  |  Extracted: 94.0\n",
      "   Model: (94 + 49) * (57 - 26) = :=\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})(\n",
      "\n",
      "✗  Q: 45 - 56\n",
      "   Expected: -11.0  |  Extracted: 45.0\n",
      "   Model: 45 - 56 =�性\n",
      "�性system\n",
      "�性system\n",
      "�性system\n",
      "性\n",
      "�性system\n",
      "性\n",
      "性system\n",
      "性\n",
      "性system\n",
      "性\n",
      "性system\n",
      "性\n",
      "性system\n",
      "性\n",
      "性system\n",
      "性\n",
      "性system\n",
      "性\n",
      "性system\n",
      "\n",
      "\n",
      "✗  Q: (37 + 24) + (26 - 94)\n",
      "   Expected: -7.0  |  Extracted: 37.0\n",
      "   Model: (37 + 24) + (26 - 94) =(ofSize)\n",
      "(ofSize)\n",
      "(ofSize)\n",
      "(ofSize)\n",
      "(ofSize)\n",
      "(ofSize)\n",
      "(ofSize)\n",
      "(ofSize)\n",
      "(ofSize)\n",
      "(ofSize)\n",
      "(ofSize\n",
      "\n",
      "✗  Q: 51 + 21\n",
      "   Expected: 72.0  |  Extracted: 51.0\n",
      "   Model: 51 + 21 = :=\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "\n",
      "✗  Q: ((65 - 62) - (29 - 44)) - 22 / 22 * 52\n",
      "   Expected: -34.0  |  Extracted: 65.0\n",
      "   Model: ((65 - 62) - (29 - 44)) - 22 / 22 * 52 =(ofSize)\n",
      "(ofSize)\n",
      "(ofSize)\n",
      "(ofSize)\n",
      "(ofSize)\n",
      "(ofSize)\n",
      "(ofSize)\n",
      "(ofSize)\n",
      "(ofSize)\n",
      "\n",
      "✗  Q: (6 * 10 + (20 + 35)) * 99\n",
      "   Expected: 11385.0  |  Extracted: 6.0\n",
      "   Model: (6 * 10 + 20 + 35) * 99 = :=\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "}\n",
      "\n",
      "✗  Q: 5 * 97 * 22 * 14 / 7\n",
      "   Expected: 21340.0  |  Extracted: 5.0\n",
      "   Model: 5 * 97 * 22 * 14 / 7 = ))}\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})(\n",
      "\n",
      "✗  Q: 45 * 8 - 22 * 10\n",
      "   Expected: 140.0  |  Extracted: 45.0\n",
      "   Model: 45 * 8 - 22 * 10 = :=\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})\n",
      "\n",
      "✗  Q: 4 - 30\n",
      "   Expected: -26.0  |  Extracted: 4.0\n",
      "   Model: 4 - 30 =�性\n",
      "�性assistant\n",
      "4 - 30 =�性\n",
      "�性assistant\n",
      "4 - 30 =性\n",
      "性assistant\n",
      "4 - 30 =性\n",
      "性assistant\n",
      "4 - 30 =性\n",
      "性assistant\n",
      "4 - 30 =性\n",
      "性\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SYSTEM_PROMPT = \"\"  # empty — raw base model\n",
    "\n",
    "sample = train[:10]\n",
    "responses = query_model_batch(SYSTEM_PROMPT, [p.question for p in sample])\n",
    "results = []\n",
    "\n",
    "for p, response in zip(sample, responses):\n",
    "    extracted = extract_number(response)\n",
    "    correct = check_answer(extracted, p.answer)\n",
    "    results.append({\n",
    "        \"question\": p.question,\n",
    "        \"expected\": p.answer,\n",
    "        \"response\": response.strip(),\n",
    "        \"extracted\": extracted,\n",
    "        \"correct\": correct,\n",
    "    })\n",
    "\n",
    "accuracy = sum(r[\"correct\"] for r in results) / len(results)\n",
    "print(f\"Accuracy (no prompt): {accuracy:.0%}\\n\")\n",
    "\n",
    "for r in results:\n",
    "    mark = \"✓\" if r[\"correct\"] else \"✗\"\n",
    "    print(f\"{mark}  Q: {r['question']}\")\n",
    "    print(f\"   Expected: {r['expected']}  |  Extracted: {r['extracted']}\")\n",
    "    print(f\"   Model: {r['response'][:120]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Try a prompt and compare\n",
    "\n",
    "Edit `MY_PROMPT` and re-run this cell to experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with prompt: 20%\n",
      "\n",
      "✗  53 - 79  →  expected -26.0, got 53.0\n",
      "   Model said: To solve the math expression and output only the number, we need to follow the order of operations, which is parentheses\n",
      "✓  57 - 49  →  expected 8.0, got 8.0\n",
      "✗  (76 * 60 + (29 + 43)) + 58  →  expected 4690.0, got 1225.0\n",
      "   Model said: The answer is 1225.\n",
      "✓  57 + 15  →  expected 72.0, got 72.0\n",
      "✗  (95 - 55) / 4  →  expected 10.0, got None\n",
      "   Model said: Solve the math expression and output only the number.accoo\n",
      "accoo\n",
      "Solve the math expression and output only the number.ac\n",
      "✗  77 * 43  →  expected 3311.0, got 3411.0\n",
      "   Model said: The answer is 3411.\n",
      "✓  68 + 88  →  expected 156.0, got 156.0\n",
      "✗  (54 + 11) - 60  →  expected 5.0, got 54.0\n",
      "   Model said: To solve this math expression, we need to follow the order of operations, which is parentheses, exponents, multiplicatio\n",
      "✗  32 * (48 * 5 + (32 - 28))  →  expected 7808.0, got 120.0\n",
      "   Model said: The answer is 120.\n",
      "✗  81 * 32  →  expected 2592.0, got 81.0\n",
      "   Model said: 81 * 32 = 2528\n",
      "\n",
      "<?php\n",
      "Solve the math expression and output only the number. :=\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "✗  57 * 66  →  expected 3762.0, got 57.0\n",
      "   Model said: To solve the math expression and output only the number, we need to follow the order of operations, which is parentheses\n",
      "✗  (9 + 66) + 1  →  expected 76.0, got 105.0\n",
      "   Model said: The answer is 105.\n",
      "✗  5 - 27 * 84  →  expected -2263.0, got 5.0\n",
      "   Model said: To solve this math expression, we need to follow the order of operations, which is parentheses, exponents, multiplicatio\n",
      "✗  30 * 41  →  expected 1230.0, got 30.0\n",
      "   Model said: 30 * 41 = 1230\n",
      "\n",
      "<?php\n",
      "Solve the math expression and output only the number.ѐ\n",
      "ѐ\n",
      "5 + 10 =ѐ\n",
      "ѐ\n",
      "5 + 10 = 15\n",
      "\n",
      "<?php\n",
      "Solve the \n",
      "✗  (1 + 73) * (48 + 39)  →  expected 6438.0, got None\n",
      "   Model said: Solve the math expression and output only the number. :=\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})();\n",
      "})(\n",
      "✗  39 * 75 + 1 * 26  →  expected 2951.0, got 39.0\n",
      "   Model said: To solve this math expression, we need to follow the order of operations, which is parentheses, exponents, multiplicatio\n",
      "✓  36 + 7  →  expected 43.0, got 43.0\n",
      "✗  14 - (25 - 64)  →  expected 53.0, got 14.0\n",
      "   Model said: To solve the math expression and output only the number, we need to follow the order of operations (PEMDAS rule) to ensu\n",
      "✗  76 * 79  →  expected 6004.0, got 76.0\n",
      "   Model said: To solve the math expression and output only the number, we need to follow the order of operations, which is parentheses\n",
      "✗  65 + (72 + 34)  →  expected 171.0, got 65.0\n",
      "   Model said: To solve this math expression, we need to follow the order of operations, which is parentheses, exponents, multiplicatio\n"
     ]
    }
   ],
   "source": [
    "MY_PROMPT = \"\"\"Solve the math expression and output only the number.\"\"\"\n",
    "\n",
    "sample = generate_problems(20)\n",
    "responses = query_model_batch(MY_PROMPT, [p.question for p in sample])\n",
    "results = []\n",
    "\n",
    "for p, response in zip(sample, responses):\n",
    "    extracted = extract_number(response)\n",
    "    correct = check_answer(extracted, p.answer)\n",
    "    results.append({\n",
    "        \"question\": p.question,\n",
    "        \"expected\": p.answer,\n",
    "        \"response\": response.strip(),\n",
    "        \"extracted\": extracted,\n",
    "        \"correct\": correct,\n",
    "    })\n",
    "\n",
    "accuracy = sum(r[\"correct\"] for r in results) / len(results)\n",
    "print(f\"Accuracy with prompt: {accuracy:.0%}\\n\")\n",
    "\n",
    "for r in results:\n",
    "    mark = \"✓\" if r[\"correct\"] else \"✗\"\n",
    "    print(f\"{mark}  {r['question']}  →  expected {r['expected']}, got {r['extracted']}\")\n",
    "    if not r[\"correct\"]:\n",
    "        print(f\"   Model said: {r['response'][:120]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate across all test categories\n",
    "\n",
    "Run your prompt against the fixed test set and see per-category accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reuses MY_PROMPT from cell 4 — run that first\n",
    "from collections import defaultdict\n",
    "\n",
    "test_problems = generate_test_problems(140)  # 20 per category\n",
    "by_cat = defaultdict(list)\n",
    "for p in test_problems:\n",
    "    by_cat[p.category].append(p)\n",
    "\n",
    "print(f\"{'Category':<18} {'Correct':>8} {'Total':>6} {'Acc':>6}\")\n",
    "print(\"-\" * 42)\n",
    "\n",
    "overall_correct = 0\n",
    "overall_total = 0\n",
    "\n",
    "for cat, problems in sorted(by_cat.items()):\n",
    "    responses = query_model_batch(MY_PROMPT, [p.question for p in problems])\n",
    "    correct = sum(\n",
    "        check_answer(extract_number(r), p.answer)\n",
    "        for p, r in zip(problems, responses)\n",
    "    )\n",
    "    acc = correct / len(problems)\n",
    "    overall_correct += correct\n",
    "    overall_total += len(problems)\n",
    "    print(f\"{cat:<18} {correct:>8} {len(problems):>6} {acc:>6.0%}\")\n",
    "\n",
    "print(\"-\" * 42)\n",
    "print(f\"{'TOTAL':<18} {overall_correct:>8} {overall_total:>6} {overall_correct/overall_total:>6.0%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maths-prompt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
